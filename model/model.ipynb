{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "import torch\n",
    "import datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset1 = pd.read_csv(\"../datasets/cleaned/troll-dataset.csv\")\n",
    "# dataset2 = pd.read_csv(\"../datasets/cleaned/WHtweets-cleaned.csv\")\n",
    "# dataset3 = pd.read_csv(\"../datasets/cleaned/metootweets-cleaned.csv\")\n",
    "\n",
    "# dataset1['label'] = 1\n",
    "# dataset2['label'] = 0\n",
    "# dataset3['label'] = 0\n",
    "\n",
    "# dataset1.rename(columns={\"content\": \"tweet\"}, inplace=True)\n",
    "# dataset2.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "# dataset3.rename(columns={\"text\": \"tweet\"}, inplace=True)\n",
    "\n",
    "# dataset1 = dataset1[['tweet', 'label']]\n",
    "# dataset2 = dataset2[['tweet', 'label']]\n",
    "# dataset3 = dataset3[['tweet', 'label']]\n",
    "\n",
    "# # Sampling the dataset1 to have the same number of samples as dataset2 plus dataset3\n",
    "# dataset1 = dataset1.sample(n=dataset2.__len__() + dataset3.__len__(), random_state=1)\n",
    "\n",
    "# dataset = pd.concat([dataset1, dataset2, dataset3], ignore_index=True)\n",
    "\n",
    "# dataset.to_csv(\"../datasets/dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../datasets/dataset.csv')\n",
    "\n",
    "print(dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = { 'non_troll' : 0, 'troll' : 1 }\n",
    "idx2label = { 0 : 'non_troll', 1 : 'troll' }\n",
    "\n",
    "dataset['label'] = dataset['label'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.sample(frac=0.8, random_state=0)\n",
    "test_data = dataset.drop(train_data.index)\n",
    "\n",
    "training = datasets.Dataset.from_pandas(train_data[['tweet', 'label']])\n",
    "validation = datasets.Dataset.from_pandas(test_data[['tweet', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the metric\n",
    "roc_auc = evaluate.load('roc_auc')\n",
    "\n",
    "# Function to compute metric\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    tensor_logits = torch.from_numpy(logits).to(device)\n",
    "    predictions = F.sigmoid(tensor_logits).cpu().detach().numpy()\n",
    "    return roc_auc.compute(references=labels,prediction_scores=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=1)\n",
    "model.to(device)\n",
    "collator = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(sample):\n",
    "    tweets = sample['tweet']\n",
    "    return tokenizer(tweets, padding=\"max_length\", truncation=True)\n",
    "\n",
    "training = training.map(tokenize_func, batched=True, batch_size=32)\n",
    "validation = validation.map(tokenize_func, batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir='./results',\n",
    "                                    num_train_epochs=5,\n",
    "                                    eval_strategy='epoch',\n",
    "                                    save_strategy='epoch',\n",
    "                                    load_best_model_at_end=True,\n",
    "                                    per_device_train_batch_size=16,\n",
    "                                    per_device_eval_batch_size=16,\n",
    "                                    warmup_steps=200,\n",
    "                                    weight_decay=0.01,\n",
    "                                    logging_dir='./logs',\n",
    "                                    logging_steps=10,\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model,\n",
    "                    args = training_args,\n",
    "                    train_dataset = training,\n",
    "                    eval_dataset = validation,\n",
    "                    data_collator = collator,\n",
    "                    compute_metrics = compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('fine-tuned-distillBert')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
