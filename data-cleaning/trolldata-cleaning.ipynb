{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load all datasets and concat it into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2973371"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"./dataset\"\n",
    "filenames = glob.glob(os.path.join(PATH, \"*.csv\"))\n",
    "dataset = pd.concat((pd.read_csv(f) for f in filenames))\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for N/A values for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_author_id : 4\n",
      "author : 0\n",
      "content : 1\n",
      "region : 8843\n",
      "language : 0\n",
      "publish_date : 0\n",
      "harvested_date : 0\n",
      "following : 0\n",
      "followers : 0\n",
      "updates : 0\n",
      "post_type : 1662425\n",
      "account_type : 363\n",
      "new_june_2018 : 0\n",
      "retweet : 0\n",
      "account_category : 0\n"
     ]
    }
   ],
   "source": [
    "column_names = dataset.columns\n",
    "\n",
    "for column in column_names:\n",
    "   print(f\"{column} : {dataset[column].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose to drop the rows that contain N/A for categories `external_author_id`, `content`, `account_type`\n",
    "\n",
    "N/A values in the `region` category can be set to unknown (an already present class)\n",
    "\n",
    "Half of the post_type rows are N/A and thus I am going to drop the category completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29872/67506064.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataset['region'].fillna(value = 'Unknown', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2973003"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna(subset=['external_author_id', 'content', 'account_type'], inplace=True)\n",
    "\n",
    "dataset.drop(labels=['post_type'], axis=1, inplace=True)\n",
    "\n",
    "dataset['region'].fillna(value = 'Unknown', inplace=True)\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique region values : ['United States' 'Unknown' 'United Arab Emirates' 'Azerbaijan'\n",
      " 'Russian Federation' 'Belarus' 'Japan' 'Samoa' 'Ukraine' 'Iraq' 'Israel'\n",
      " 'India' 'Germany' 'Italy' 'France' 'United Kingdom' 'Spain' 'Egypt'\n",
      " 'Iran, Islamic Republic of' 'Afghanistan' 'Saudi Arabia' 'Mexico'\n",
      " 'Canada' 'Malaysia' 'Sweden' 'Denmark' 'Switzerland' 'Greece'\n",
      " 'Czech Republic' 'Finland' 'Latvia' 'Estonia' 'Turkey' 'Serbia'\n",
      " 'Hong Kong' 'Austria']\n",
      "Unique langauge values : ['English' 'Italian' 'Lithuanian' 'Norwegian' 'French' 'Spanish'\n",
      " 'Romanian' 'Icelandic' 'German' 'Estonian' 'Catalan' 'Somali' 'Arabic'\n",
      " 'Hungarian' 'Vietnamese' 'Portuguese' 'Latvian' 'Tagalog (Filipino)'\n",
      " 'Swedish' 'Dutch' 'Uzbek' 'Farsi (Persian)' 'Kurdish' 'Croatian'\n",
      " 'Japanese' 'Albanian' 'Pushto' 'Czech' 'Finnish' 'Danish' 'Slovak'\n",
      " 'Korean' 'Malay' 'Polish' 'LANGUAGE UNDEFINED' 'Russian' 'Ukrainian'\n",
      " 'Macedonian' 'Bulgarian' 'Serbian' 'Turkish' 'Indonesian' 'Hebrew'\n",
      " 'Slovenian' 'Hindi' 'Urdu' 'Greek' 'Thai' 'Gujarati'\n",
      " 'Traditional Chinese' 'Kannada' 'Tamil' 'Simplified Chinese' 'Bengali'\n",
      " 'Telugu' 'Malayalam']\n"
     ]
    }
   ],
   "source": [
    "# printing all unique values in region and langauge categories\n",
    "print(f\"Unique region values : {dataset['region'].unique()}\")\n",
    "print((f\"Unique langauge values : {dataset['language'].unique()}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are tweets in many languages. I want to only focus on English tweets on this project. I will drop rest of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2128608"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[dataset['language'] == 'English']\n",
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some more data exploration to understand the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes : \n",
      "['NewsFeed' 'LeftTroll' 'RightTroll' 'HashtagGamer' 'Fearmonger'\n",
      " 'NonEnglish' 'Unknown' 'Commercial'] \n",
      "\n",
      "Unique account types : \n",
      "['local' 'left' 'Right' 'Hashtager' 'Koch' 'Russian' '?' 'news' 'right'\n",
      " 'German' 'Commercial' 'Italian' 'Arabic' 'French' 'Ebola ' 'Spanish'\n",
      " 'Portuguese' 'ZAPOROSHIA'] \n",
      "\n",
      "total authors : 2161\n"
     ]
    }
   ],
   "source": [
    "# Unique account_categories\n",
    "print(f\"Unique classes : \\n{dataset['account_category'].unique()} \\n\")\n",
    "\n",
    "# Unique account_type\n",
    "print(f\"Unique account types : \\n{dataset['account_type'].unique()} \\n\")\n",
    "\n",
    "# Total authors\n",
    "print(f\"total authors : {dataset['author'].unique().__len__()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total twitter links : 1838999\n",
      "Total picture links : 41\n",
      "Total other links : 321\n",
      "http://false\n",
      "https://…\n",
      "https://…\n",
      "https://youNas\n",
      "https://…\n",
      "http://...\n",
      "http://bit.ly/1ux8KLv\n",
      "http://https://t.co/Un0Ml9tTpC\n",
      "https://goo.gl/w0xLa1\n",
      "https://…\n"
     ]
    }
   ],
   "source": [
    "url_pattern = re.compile(r\"(?:(?:https?://)?pic.twitter.com/|https?://t\\S+|https?://\\S+)\")\n",
    "\n",
    "# Finding all links in the values of 'content' and storing them in a list\n",
    "\n",
    "twitter_urls = []\n",
    "picture_urls = []\n",
    "other_urls = []\n",
    "\n",
    "for value in dataset['content']:\n",
    "    urls = url_pattern.findall(value)\n",
    "    for url in urls:\n",
    "        if re.match(r\"https?://t\\S+\", url):\n",
    "            twitter_urls.append(url)\n",
    "        elif re.match(r\"(?:https?://)?pic.twitter.com/\", url):\n",
    "            picture_urls.append(url)\n",
    "        else:\n",
    "            other_urls.append(url)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(f\"Total twitter links : {twitter_urls.__len__()}\")\n",
    "print(f\"Total picture links : {picture_urls.__len__()}\")\n",
    "print(f\"Total other links : {other_urls.__len__()}\")\n",
    "\n",
    "for url in other_urls[:10]:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see there is mutiple types of links. I decided to make a column category 'Link' that has classes 'tweet_link', 'picture_link', 'other_link', 'no_link'\n",
    "\n",
    "Some links are not present completely and end with '...'. I try my best to classify these links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'Link Type' to store the type of link\n",
    "dataset['link_type'] = 'None'\n",
    "\n",
    "# Filling the 'Link Type' column with the type of link\n",
    "for index, value in dataset['content'].items():\n",
    "    urls = url_pattern.findall(value)\n",
    "    for url in urls:\n",
    "        if re.match(r\"https?://t\\S+\", url):\n",
    "            dataset.at[index, 'link_type'] = 'tweet_link'\n",
    "        elif re.match(r\"(?:https?://)?pic.twitter.com/\", url):\n",
    "            dataset.at[index, 'link_type'] = 'picture_link'\n",
    "        elif re.match(r\"https?://\\S+\", url):\n",
    "            dataset.at[index, 'link_type'] = 'other_link'\n",
    "            \n",
    "    if len(urls) == 0:\n",
    "            dataset.at[index, 'link_type'] = 'no_link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_author_id</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>harvested_date</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>updates</th>\n",
       "      <th>account_type</th>\n",
       "      <th>new_june_2018</th>\n",
       "      <th>retweet</th>\n",
       "      <th>account_category</th>\n",
       "      <th>link_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.494112e+09</td>\n",
       "      <td>DAILYSANJOSE</td>\n",
       "      <td>#sports Ex-Stanford player Stanley Wilson II s...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>6/27/2016 14:39</td>\n",
       "      <td>6/27/2016 14:39</td>\n",
       "      <td>11955</td>\n",
       "      <td>13225</td>\n",
       "      <td>20394</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>no_link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.494112e+09</td>\n",
       "      <td>DAILYSANJOSE</td>\n",
       "      <td>The Mountain View gets ready to close its door...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>6/27/2016 14:56</td>\n",
       "      <td>6/27/2016 14:56</td>\n",
       "      <td>11955</td>\n",
       "      <td>13225</td>\n",
       "      <td>20395</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>no_link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.494112e+09</td>\n",
       "      <td>DAILYSANJOSE</td>\n",
       "      <td>#politics Supreme Court strikes down Texas abo...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>6/27/2016 14:59</td>\n",
       "      <td>6/27/2016 14:59</td>\n",
       "      <td>11955</td>\n",
       "      <td>13225</td>\n",
       "      <td>20396</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>no_link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.494112e+09</td>\n",
       "      <td>DAILYSANJOSE</td>\n",
       "      <td>#health Supreme Court strikes down Texas abort...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>6/27/2016 15:01</td>\n",
       "      <td>6/27/2016 15:01</td>\n",
       "      <td>11955</td>\n",
       "      <td>13225</td>\n",
       "      <td>20397</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>no_link</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.494112e+09</td>\n",
       "      <td>DAILYSANJOSE</td>\n",
       "      <td>#sports Lochte Fails to Qualify for Rio in Sig...</td>\n",
       "      <td>United States</td>\n",
       "      <td>English</td>\n",
       "      <td>6/27/2016 15:24</td>\n",
       "      <td>6/27/2016 15:24</td>\n",
       "      <td>11955</td>\n",
       "      <td>13225</td>\n",
       "      <td>20398</td>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NewsFeed</td>\n",
       "      <td>no_link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   external_author_id        author  \\\n",
       "0        2.494112e+09  DAILYSANJOSE   \n",
       "1        2.494112e+09  DAILYSANJOSE   \n",
       "2        2.494112e+09  DAILYSANJOSE   \n",
       "3        2.494112e+09  DAILYSANJOSE   \n",
       "4        2.494112e+09  DAILYSANJOSE   \n",
       "\n",
       "                                             content         region language  \\\n",
       "0  #sports Ex-Stanford player Stanley Wilson II s...  United States  English   \n",
       "1  The Mountain View gets ready to close its door...  United States  English   \n",
       "2  #politics Supreme Court strikes down Texas abo...  United States  English   \n",
       "3  #health Supreme Court strikes down Texas abort...  United States  English   \n",
       "4  #sports Lochte Fails to Qualify for Rio in Sig...  United States  English   \n",
       "\n",
       "      publish_date   harvested_date  following  followers  updates  \\\n",
       "0  6/27/2016 14:39  6/27/2016 14:39      11955      13225    20394   \n",
       "1  6/27/2016 14:56  6/27/2016 14:56      11955      13225    20395   \n",
       "2  6/27/2016 14:59  6/27/2016 14:59      11955      13225    20396   \n",
       "3  6/27/2016 15:01  6/27/2016 15:01      11955      13225    20397   \n",
       "4  6/27/2016 15:24  6/27/2016 15:24      11955      13225    20398   \n",
       "\n",
       "  account_type  new_june_2018  retweet account_category link_type  \n",
       "0        local              1        0         NewsFeed   no_link  \n",
       "1        local              1        0         NewsFeed   no_link  \n",
       "2        local              1        0         NewsFeed   no_link  \n",
       "3        local              1        0         NewsFeed   no_link  \n",
       "4        local              1        0         NewsFeed   no_link  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now clean the links of the regex since they add no value to classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing url's from the content\n",
    "for index, value in dataset['content'].items():\n",
    "    dataset.at[index, 'content'] = url_pattern.sub('', value)\n",
    "    \n",
    "for index, value in dataset['content'].items():\n",
    "    dataset.at[index, 'content'] = re.sub(r\"htt\\S*...\", '', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a `has_emoji` column and Removing emoji's from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "                            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                            u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U00002702-\\U000027B0\"\n",
    "                            u\"\\U000024C2-\\U0001F251\"\n",
    "                            u\"\\U0001f926-\\U0001f937\"\n",
    "                            u\"\\U00010000-\\U0010ffff\"\n",
    "                            u\"\\u2640-\\u2642\"\n",
    "                            u\"\\u2600-\\u2B55\"\n",
    "                            u\"\\u200d\"\n",
    "                            u\"\\u23cf\"\n",
    "                            u\"\\u23e9\"\n",
    "                            u\"\\u231a\"\n",
    "                            u\"\\ufe0f\"  # dingbats\n",
    "                            u\"\\u3030\"\n",
    "                            \"]+\", flags=re.UNICODE)\n",
    "\n",
    "dataset['has_emoji'] = 0\n",
    "\n",
    "for index, value in dataset['content'].items():\n",
    "    if emoji_pattern.search(value):\n",
    "        dataset.at[index, 'has_emoji'] = 1\n",
    "    \n",
    "    dataset.at[index, 'content'] = emoji_pattern.sub('', value)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2128608"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#sports Ex-Stanford player Stanley Wilson II shot while breaking in to home\n",
      "The Mountain View gets ready to close its doors for good  #SanJose\n",
      "#politics Supreme Court strikes down Texas abortion clinic regulation\n",
      "#health Supreme Court strikes down Texas abortion clinic regulation\n",
      "#sports Lochte Fails to Qualify for Rio in Signature Race\n",
      "#sports Women's gymnastics: Simone Biles cruises into San Jose's Olympic trials\n",
      "#SanJose San Francisco Holds Annual Gay Pride Parade\n",
      "#sports Draymond Green, Klay Thompson, Harrison Barnes all make 2016 Olympic team\n",
      "#SanJose Warriors Send Three to Olympics\n",
      "#politics Donald Trump's $10 email: Does he have the magic to refill campaign coffers?\n"
     ]
    }
   ],
   "source": [
    "for content in dataset['content'][:10]:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['content'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataset as a csv for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('troll_dataset.csv', float_format='%.f', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
